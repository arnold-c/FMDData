import{_ as a,c as t,o,aA as l}from"./chunks/framework.BSFqMKy6.js";const u=JSON.parse('{"title":"Data Cleaning Process","description":"","frontmatter":{},"headers":[],"relativePath":"cleaning-process.md","filePath":"cleaning-process.md","lastUpdated":null}'),s={name:"cleaning-process.md"};function n(i,e,c,r,p,d){return o(),t("div",null,e[0]||(e[0]=[l('<h1 id="Data-Cleaning-Process" tabindex="-1">Data Cleaning Process <a class="header-anchor" href="#Data-Cleaning-Process" aria-label="Permalink to &quot;Data Cleaning Process {#Data-Cleaning-Process}&quot;">​</a></h1><p>This document outlines the data cleaning process for the FMDData project. The process is orchestrated by the <code>scripts/icar-cleaning.jl</code> script, which uses two distinct cleaning pipelines to handle variations in the source data formats.</p><h3 id="Cleaning-Pipelines" tabindex="-1">Cleaning Pipelines <a class="header-anchor" href="#Cleaning-Pipelines" aria-label="Permalink to &quot;Cleaning Pipelines {#Cleaning-Pipelines}&quot;">​</a></h3><p>The <code>scripts/icar-cleaning.jl</code> script segregates files into two main cleaning workflows:</p><ol><li><p><strong><code>all_cleaning_steps</code></strong>: The standard pipeline for NADCP and post-2019 reports.</p></li><li><p><strong><code>all_2019_cleaning_steps</code></strong>: A specialized pipeline for the 2019 annual report data, which has a different structure.</p></li></ol><hr><h3 id="Main-Workflow:-all_cleaning_steps" tabindex="-1">Main Workflow: <code>all_cleaning_steps</code> <a class="header-anchor" href="#Main-Workflow:-all_cleaning_steps" aria-label="Permalink to &quot;Main Workflow: `all_cleaning_steps` {#Main-Workflow:-all_cleaning_steps}&quot;">​</a></h3><p>This function, defined in <code>src/icar-cleaning/wrapper-functions.jl</code>, is a multi-stage process for loading, validating, calculating, and saving the data.</p><p><strong>Step 1: Setup and Logging</strong></p><ul><li><p>A <code>logfiles</code> directory and a log file for the specific dataset are created.</p></li><li><p>Each step is wrapped in a <code>_log_try_error</code> block to capture warnings and errors without halting execution.</p></li></ul><p><strong>Step 2: Initial Loading and Sanitization</strong></p><ol><li><p><strong><code>load_csv</code></strong>: Loads the raw CSV file from <code>inputs/ICAR-Reports/extracted-seroprevalence-tables/</code> into a DataFrame.</p></li><li><p><strong><code>clean_colnames</code></strong>: Standardizes column names by converting to <code>snake_case</code>, removing special characters, and trimming whitespace.</p></li><li><p><strong><code>rename_aggregated_pre_post_counts</code></strong>: Renames columns for pre- and post-vaccination counts for clarity.</p></li><li><p><strong><code>correct_all_state_names</code></strong>: Standardizes state names using a predefined mapping in <code>src/icar-cleaning/state-keys.jl</code>.</p></li></ol><p><strong>Step 3: Data Validation</strong></p><p>A series of validation checks are performed to ensure data integrity.</p><ul><li><p><strong>Structural Checks</strong>:</p><ul><li><p><code>check_duplicated_column_names</code>: Ensures no duplicate column names exist after cleaning.</p></li><li><p><code>check_duplicated_states</code>: Verifies that each state appears only once.</p></li></ul></li><li><p><strong>Content and Completeness Checks</strong>:</p><ul><li><p><code>check_missing_states</code>: Confirms that all expected states are present.</p></li><li><p><code>check_allowed_serotypes</code>: Validates that serotype columns match a predefined list.</p></li><li><p><code>check_seroprevalence_as_pct</code>: Ensures seroprevalence values are percentages.</p></li><li><p><code>check_aggregated_pre_post_counts_exist</code> and <code>check_pre_post_exists</code>: Confirms the presence of essential columns for vaccination counts.</p></li></ul></li></ul><p><strong>Step 4: Totals Calculation and Verification</strong></p><ol><li><p><strong><code>has_totals_row</code></strong>: Checks for the existence of a &quot;Total&quot; row.</p></li><li><p><strong><code>calculate_all_totals</code></strong>: Independently calculates totals for all numeric columns.</p></li><li><p><strong><code>all_totals_check</code></strong>: Compares calculated totals with existing totals. If they do not match, a warning is logged, and the calculated totals are used. If no totals row exists, the calculated one is added.</p></li></ol><p><strong>Step 5: Core Calculations and Finalization</strong></p><ol><li><p><strong><code>calculate_state_counts</code> &amp; <code>calculate_state_seroprevalence</code></strong>: Calculates state-level counts and seroprevalence.</p></li><li><p><strong><code>check_calculated_values_match_existing</code></strong>: Compares these calculations with the original values and logs any discrepancies.</p></li><li><p><strong><code>select_calculated_cols!</code> &amp; <code>select_calculated_totals!</code></strong>: Replaces the original columns with the calculated ones.</p></li><li><p><strong><code>sort_columns!</code> &amp; <code>sort_states!</code></strong>: Sorts columns and rows for consistency.</p></li></ol><p><strong>Step 6: Output</strong></p><p>The cleaned DataFrame is saved as a new CSV file in the <code>data/icar-seroprevalence/cleaned/</code> directory.</p><hr><h3 id="Specialized-Workflow:-all_2019_cleaning_steps" tabindex="-1">Specialized Workflow: <code>all_2019_cleaning_steps</code> <a class="header-anchor" href="#Specialized-Workflow:-all_2019_cleaning_steps" aria-label="Permalink to &quot;Specialized Workflow: `all_2019_cleaning_steps` {#Specialized-Workflow:-all_2019_cleaning_steps}&quot;">​</a></h3><p>The 2019 data requires a different cleaning process due to its unique structure.</p><ol><li><p><strong>No Totals Row</strong>: The 2019 tables do not contain a &quot;Total&quot; row. The function will log an error if one is found.</p></li><li><p><strong>Duplicate States</strong>: The 2019 data may contain multiple rows for the same state. The <code>check_duplicated_states</code> validation step is skipped in this pipeline.</p></li><li><p><strong>Conditional Calculations</strong>: The core calculations (<code>calculate_state_counts</code>, <code>calculate_state_seroprevalence</code>) are only performed if aggregated count columns are present.</p></li></ol><h3 id="Summary" tabindex="-1">Summary <a class="header-anchor" href="#Summary" aria-label="Permalink to &quot;Summary {#Summary}&quot;">​</a></h3><p>The FMDData project uses two distinct cleaning pipelines to handle different data formats:</p><ul><li><p><strong><code>all_cleaning_steps</code></strong>: A comprehensive pipeline for structured tables with a single row per state and a totals row.</p></li><li><p><strong><code>all_2019_cleaning_steps</code></strong>: A flexible pipeline for the 2019 report tables, which lack totals and may have multiple entries per state.</p></li></ul><p>This approach allows for robust and accurate cleaning of various data formats.</p>',29)]))}const _=a(s,[["render",n]]);export{u as __pageData,_ as default};
